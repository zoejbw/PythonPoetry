{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pronouncing as pr\n",
    "import random\n",
    "from random import sample \n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import spacy\n",
    "from simpleneighbors import SimpleNeighbors\n",
    "import editdistance\n",
    "from flat import document, shape, rgba\n",
    "from IPython.display import Image, display\n",
    "def show(page):\n",
    "    display(Image(page.image(kind='rgba').png()))\n",
    "from bezmerizing import smooth_point_path, fancy_curve\n",
    "import numpy as np\n",
    "from numpy.random import uniform, normal, choice\n",
    "import tracery\n",
    "from tracery.modifiers import base_english"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [rgba(220, 0, 0, 255), # red\n",
    "          rgba(170, 0, 0, 255), # dark red\n",
    "          rgba(0, 0, 220, 255), # blue\n",
    "          rgba(0, 0, 170, 255), # dark blue\n",
    "          rgba(250, 250, 250, 255), # white\n",
    "          rgba(255, 255, 0, 255), # yellow\n",
    "          rgba(0, 150, 0, 255), # green\n",
    "         ]\n",
    "starcolors = [rgba(250, 250, 250, 255), # white\n",
    "          rgba(255, 255, 0, 255), # yellow\n",
    "             ]\n",
    "              \n",
    "horizontal = [1, 2, 2, 3, 3, 4, 5, 10, 13, 15, 20]\n",
    "vertical = [1, 2, 2, 3, 3, 4, 5]\n",
    "starnum = [0, 1, 1, 2, 3, 4, 5, 7, 10, 13, 15, 25, 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def makeFlag():\n",
    "    h = 120\n",
    "    w = 200\n",
    "    d = document(w, h, 'mm') # create a document 100mm x 100mm (can replace 'mm' with 'pt')\n",
    "    page = d.addpage() # add a page\n",
    "    mycolors = sample(colors, 3)\n",
    "\n",
    "    #add base\n",
    "    figure = shape()\n",
    "    figure.fill(mycolors[0])\n",
    "    figure.stroke(rgba(255, 255, 255, 255))\n",
    "    figure.width(0)\n",
    "    rect = figure.rectangle(0, 0, w, h)\n",
    "    page.place(rect)\n",
    "\n",
    "    #add horizontal stripes\n",
    "    mycolor = mycolors[1]\n",
    "    stripes = random.choice(horizontal)\n",
    "    sheight = h/stripes\n",
    "    i = 0\n",
    "    for stripe in range(stripes):\n",
    "        figure = shape()\n",
    "        figure.fill(mycolor)\n",
    "        figure.stroke(rgba(255, 255, 255, 255))\n",
    "        figure.width(0)\n",
    "        rect = figure.rectangle(0, i*sheight*2, w, sheight)\n",
    "        page.place(rect)\n",
    "        i = i + 1\n",
    "\n",
    "    #add vertical stripes\n",
    "    mycolor = mycolors[2]\n",
    "    stripes = random.choice(vertical)\n",
    "    swidth = w/stripes\n",
    "    i = 0\n",
    "    for stripe in range(stripes):\n",
    "        if (stripes == 2):\n",
    "            myh = (random.randint(25, 100))\n",
    "        else:\n",
    "            myh = h\n",
    "        figure = shape()\n",
    "        figure.fill(mycolor)\n",
    "        figure.stroke(rgba(255, 255, 255, 255))\n",
    "        figure.width(0)\n",
    "        rect = figure.rectangle(i*swidth*2, 0, swidth, myh)\n",
    "        page.place(rect)\n",
    "        i = i + 1\n",
    "\n",
    "    #add stars\n",
    "    mycolor = random.choice(starcolors)\n",
    "    stars = random.choice(starnum)\n",
    "    for _ in range(stars):\n",
    "        figure = shape()\n",
    "        figure.fill(mycolor)\n",
    "        figure.stroke(rgba(255, 255, 255, 255))\n",
    "        figure.width(0)\n",
    "        x = random.randint(5, (w - 15))\n",
    "        y = random.randint(5, (h - 15))\n",
    "        cos = [\n",
    "               4+x, 4+y,\n",
    "               5+x, 0+y,\n",
    "               6+x, 4+y,\n",
    "               10+x, 4+y,\n",
    "               7+x, 6+y,\n",
    "               8+x, 10+y,\n",
    "               5+x, 8+y,\n",
    "               2+x, 10+y,\n",
    "               3+x, 6+y,\n",
    "               0+x, 4+y\n",
    "                ]   \n",
    "        star = figure.polygon(cos)\n",
    "        page.place(star)\n",
    "\n",
    "\n",
    "    show(page) # show the page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Anthem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def markovModel(n, seq):\n",
    "    model = {}\n",
    "    for i in range (len(seq)-n):\n",
    "        ngram = tuple(seq[i:i+n])\n",
    "        nextItem = seq[i+n]\n",
    "        if ngram not in model:\n",
    "            model[ngram] = []\n",
    "        model[ngram].append(nextItem)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen (n, model, start, end):\n",
    "    output = list(start)\n",
    "    for i in range(100):\n",
    "        start = tuple(output[-n:])\n",
    "        nextItem = random.choice(model[start])\n",
    "        if nextItem == end:\n",
    "            break\n",
    "        else:\n",
    "            output.append(nextItem)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns = open(\"plaintext/nouns.txt\").read().split()\n",
    "# includes all countires, and states/provinces of China, India, USA, Indonesia, Brazil\n",
    "countries = open(\"plaintext/countries.txt\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "lookup = SimpleNeighbors(300)\n",
    "for item in nlp.vocab:\n",
    "    if item.has_vector and item.prob > -15 and item.is_lower:\n",
    "        lookup.add_one(item.text, item.vector)\n",
    "lookup.build()\n",
    "\n",
    "def vec(s):\n",
    "    return nlp.vocab[s].vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makePledge():\n",
    "    starts = ['am','pa','an','be','gr','gu','in','mo','we','mi','no','ce','do','au','so', 'no', 'ea', 'ne', 'un']\n",
    "    country = \"\"\n",
    "    while (len(country) < 5):\n",
    "        country = ''.join(gen(2, markovModel(2, countries), random.choice(starts), \"\\n\"))\n",
    "\n",
    "    #finds traits with relationship of liberty and justice\n",
    "    traita = random.choice(nouns)\n",
    "    lib_to_jus = vec(\"liberty\") - vec(\"justice\")\n",
    "    traitb = lookup.nearest(lib_to_jus + vec(traita))[0]\n",
    "\n",
    "    #goes to next item in search if traits are the same\n",
    "    x = 1\n",
    "    while (traita == traitb):\n",
    "        traitb = lookup.nearest(lib_to_jus + vec(traita))[x]\n",
    "        x = x + 1\n",
    "\n",
    "    rules = {\n",
    "        \"output\": \" #intro.capitalize# \\\"#pledge#\\\" \\n#outro#\",\n",
    "        \"intro\" : \"The Pledge of Allegiance to the Flag: \\n\",\n",
    "        \"pledge\" : \"#1#\\n #2#\\n #3#\\n #4#\\n #5#\\n #god##6#\\n #7#\",\n",
    "        \"1\":[\"I pledge allegiance to the flag,\",\"I pledge allegiance to my flag,\"],\n",
    "        \"2\":\"of #country.capitalize#,\",\n",
    "        \"country\" : country,\n",
    "        \"3\":\"and to the #type#,\",\n",
    "        \"type\": [\"republic\",\"democracy\",\"monarchy\",\"federation\",\"government\"],\n",
    "        \"4\" : \"for which it stands,\",\n",
    "        \"5\":\"one nation,\",\n",
    "        \"god\":[\"\",\"\",\"under God,\\n \",\"under Gods,\\n \",\"under Goddess,\\n \"],\n",
    "        \"6\":\"indivisible,\",\n",
    "        \"7\":\"with #traita# and #traitb# for all.\",\n",
    "        \"traita\": traita,\n",
    "        \"traitb\": traitb,\n",
    "        \"outro\"  : \" should be #said# by #action# facing #towards# #direction# with #parta# #over# #partb#.\",\n",
    "        \"said\" : [\"said\",\"recited\",\"rendered\"],\n",
    "        \"action\" : [\"sitting\",\"standing\",\"kneeling\",\"bowing\"],\n",
    "        \"towards\" : [\"toward\",\"away from\",\"opposite\",\"90 degrees from\",\"\"],\n",
    "        \"direction\" : [\"the flag\",\"the flag\",\"the capital\",\"the highest authority\",\"the door\"],\n",
    "        \"parta\" : [\"the #lr# hand\",\"both hands\", \"the #lr# index finger\"],\n",
    "        \"lr\" : [\"left\", \"right\"],\n",
    "        \"over\" : [\"crossing\", \"over\", \"covering\"],\n",
    "        \"partb\" : [\"heart\",\"chest\",\"head\",\"#lr# eye\",\"mouth\",\"body\",\"#lr# shoulder\"]\n",
    "    }\n",
    "\n",
    "    grammar = tracery.Grammar(rules)\n",
    "    grammar.add_modifiers(base_english)\n",
    "    pledge = grammar.flatten(\"#pledge#\")\n",
    "    output = grammar.flatten(\"#output#\")\n",
    "    x = [output,pledge,country]\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Phoenetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide(l):  \n",
    "    output = []\n",
    "    lengths = [3,4,5]\n",
    "    x = random.choice(lengths)\n",
    "    for i in range(0, len(l), x):  \n",
    "        output.append(l[i:i + x])\n",
    "    #print(output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phonit(text):\n",
    "    \n",
    "    text = text.split(\"\\n\")\n",
    "\n",
    "    lines = []\n",
    "    for line in text:\n",
    "        line = line.strip()\n",
    "        line = line.lower()\n",
    "        if len(line) > 0:\n",
    "            lines.append(line)\n",
    "\n",
    "    ends = []\n",
    "    for line in lines:\n",
    "        ends.append(line[-1:])\n",
    "\n",
    "    fullphon = []\n",
    "    phonemes = []\n",
    "    for line in lines:\n",
    "        doc = nlp(line)\n",
    "        for item in doc:\n",
    "            phones = pr.phones_for_word(item.text)\n",
    "            if len(phones) > 0:\n",
    "                individual_phones = phones[0].split()\n",
    "                add = []\n",
    "                for item in individual_phones:\n",
    "                    add.append(item)\n",
    "                phonemes.extend(add)\n",
    "        fullphon.append(phonemes)\n",
    "        phonemes = []\n",
    "\n",
    "    this = \"\"\n",
    "    search = \"\"\n",
    "    x = 0\n",
    "    # ' '.join(part)\n",
    "    for line in fullphon:\n",
    "        parts = divide(line)\n",
    "        for part in parts:\n",
    "            target = part\n",
    "            with_distances = [(word, phones, editdistance.eval(phones.split(), target)) for word, phones in pr.pronunciations]\n",
    "            sorted_by_dist = sorted(with_distances, key=lambda x: x[2])\n",
    "            lowest_dist = min([item[2] for item in with_distances])\n",
    "            only_lowest = [item for item in sorted_by_dist if item[2] == lowest_dist]\n",
    "            closest = random.choice(only_lowest)\n",
    "        #print(closest)\n",
    "            this = this + \" \" + closest[0]\n",
    "        this = this + ends[x] + \"\\n\"\n",
    "        x = x + 1\n",
    "    return(this)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAFUCAYAAADYoB3HAAAIUklEQVR4nO3WoXFUAQBF0e+RSSFUQAt4+oAO1lEJZaBjMwgYDBFrgkREsKQI9oZ5HHH8U2/u8ek4LgDXdn86XZ6engCu6seXh9/HSx8e8H8QN0BB3AAZcQMUxA2QETdAQdwAGXEDFMQNkBE3QEHcABlxAxTEDZARN0BB3AAZcQMUxA2QETdAQdwAGXEDFMQNkBE3QEHcABlxAxTEDZARN0BB3AAZcQMUxA2QETdAQdwAGXEDFMQNkBE3QEHcABlxAxTEDZARN0BB3AAZcQMUxA2QETdAQdwAGXEDFMQNkBE3QEHcABlxAxTEDZARN0BB3AAZcQMUxA2QETdAQdwAGXEDFMQNkBE3QEHcABlxAxTEDZARN0BB3AAZcQMUxA2QETdAQdwAGXEDFMQNkBE3QEHcABlxAxTEDZARN0BB3AAZcQMUxA2QETdAQdwAGXEDFMQNkBE3QEHcABlxAxTEDZARN0BB3AAZcQMUxA2QETdAQdwAGXEDFMQNkBE3QEHcABlxAxTEDZARN0BB3AAZcQMUxA2QETdAQdwAGXEDFMQNkBE3QEHcABlxAxTEDZARN0BB3AAZcQMUxA2QETdAQdwAGXEDFMQNkBE3QEHcABlxAxTEDZARN0BB3AAZcQMUxA2QETdAQdwAGXEDFMQNkBE3QEHcABlxAxTEDZARN0BB3AAZcQMUxA2QETdAQdwAGXEDFMQNkBE3QEHcABlxAxTEDZARN0BB3AAZcQMUxA2QETdAQdwAGXEDFMQNkBE3QEHcABlxAxTEDZARN0BB3AAZcQMUxA2QETdAQdwAGXEDFMQNkBE3QEHcABlxAxTEDZARN0BB3AAZcQMUxA2QETdAQdwAGXEDFMQNkBE3QEHcABlxAxTEDZARN0BB3AAZcQMUxA2QETdAQdwAGXEDFMQNkBE3QEHcABlxAxTEDZARN0BB3AAZcQMUxA2QETdAQdwAGXEDFMQNkBE3QEHcABlxAxTEDZARN0BB3AAZcQMUxA2QETdAQdwAGXEDFMQNkBE3QEHcABlxAxTEDZARN0BB3AAZcQMUxA2QETdAQdwAGXEDFMQNkBE3QEHcABlxAxTEDZARN0BB3AAZcQMUxA2QETdAQdwAGXEDFMQNkBE3QEHcABlxAxTEDZARN0BB3AAZcQMUxA2QETdAQdwAGXEDFMQNkBE3QEHcABlxAxTEDZARN0BB3AAZcQMUxA2QETdAQdwAGXEDFMQNkBE3QEHcABlxAxTEDZARN0BB3AAZcQMUxA2QETdAQdwAGXEDFMQNkBE3QEHcABlxAxTEDZARN0BB3AAZcQMUxA2QETdA4eHrWdwADXEDFM7nX+IGaIgboCBugIy4AQriBsiIG6AgboCMuAEK4gbIiBugIG6AjLgBCuIGyIgboCBugIy4AQriBsiIG6AgboCMuAEK4gbIiBugIG6AjLgBCuIGyIgboCBugIy4AQriBsiIG6AgboCMuAEK4gbIiBugIG6AjLgBCuIGyIgboCBugIy4AQriBsiIG6AgboCMuAEK4gbIiBugIG6AjLgBCuIGyIgboCBugIy4AQriBsiIG6AgboDMu1cfLre33wGu6ubm809xAyTeHu8vx/EN4MruHsUNkBA3QEPcABFxAzTEDRARN0BD3AARcQM0xA0QETdAQ9wAEXEDNMQNEBE3QEPcABFxAzTEDRARN0BD3AARcQM0xA0QETdAQ9wAEXEDNMQNEBE3QEPcABFxAzTEDRARN0BD3AARcQM0xA0QETdAQ9wAEXEDNMQNEBE3QEPcABFxAzTEDRARN0BD3AARcQM0xA0QETdAQ9wAEXEDNMQNEBE3QEPcABFxAzTEDRARN0BD3AARcQM0xA0QETdAQ9wAEXEDNMQNEBE3QEPcABFxAzTEDRARN0BD3AARcQM0xA0QETdAQ9wAEXEDNMQNEBE3QEPcABFxAzTEDRARN0BD3AARcQM0xA0QETdAQ9wAEXEDNMQNEBE3QEPcABFxAzTEDRARN0BD3AARcQM0xA0QETdAQ9wAEXEDNMQNEBE3QEPcABFxAzTEDRARN0BD3AARcQM0xA0QETdAQ9wAEXEDNMQNEBE3QEPcABFxAzTEDRARN0BD3AARcQM0xA0QETdAQ9wAEXEDNMQNEBE3QEPcABFxAzTEDRARN0BD3AARcQM0xA0QETdAQ9wAEXEDNMQNEBE3QEPcABFxAzTEDRARN0BD3AARcQM0xA0QETdA4zluTsfrC8C1vTk+/gOnB+x7jpuXHwEA8LeIGwBgirgBAKaIGwBgirgBAKaIGwBgirgBAKaIGwBgirgBAKaIGwBgirgBAKaIGwBgirgBAKaIGwBgirgBAKaIGwBgirgBAKaIGwBgirgBAKaIGwBgirgBAKaIGwBgirgBAKaIGwBgirgBAKaIGwBgirgBAKaIGwBgirgBAKaIGwBgirgBAKaIGwBgirgBAKaIGwBgirgBAKaIGwBgirgBAKaIGwBgirgBAKaIGwBgirgBAKaIGwBgirgBAKaIGwBgirgBAKaIGwBgirgBAKaIGwBgirgBAKaIGwBgirgBAKaIGwBgirgBAKaIGwBgirgBAKaIGwBgirgBAKaIGwBgirgBAKaIGwBgirgBAKaIGwBgirgBAKaIGwBgirgBAKaIGwBgirgBAKaIGwBgirgBAKaIGwBgirgBAKaIGwBgirgBAKaIGwBgirgBAKaIGwBgirgBAKaIGwBgirgBAKaIGwBgirgBAKaIGwBgirgBAKaIGwBgirgBAKaIGwBgirgBAKaIGwBgirgBAKaIGwBgirgBAKaIGwBgirgBAKaIGwBgirgBAKaIGwBgyt3jH9g2oqNjDYpSAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The Pledge of Allegiance to the Flag: \n",
      " \"I pledge allegiance to my flag,\n",
      " of Ambon,\n",
      " and to the federation,\n",
      " for which it stands,\n",
      " one nation,\n",
      " under God,\n",
      " indivisible,\n",
      " with invasion and infiltration for all.\" \n",
      " should be rendered by bowing facing away from the flag with both hands over mouth.\n"
     ]
    }
   ],
   "source": [
    "makeflag()\n",
    "output = makePledge()\n",
    "print(output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " pledge elisa stu flagg,\n",
      " of ambon,\n",
      " undue eidem ochra o,\n",
      " faure which it's tan does,\n",
      " wunsch ration,\n",
      " endive isetan ur,\n",
      " winn vaden undone fault patient kroll.\n",
      "\n",
      " aisle eka liege 'n toothed afoul ag,\n",
      " of ambon,\n",
      " and tomb adee mok ros e,\n",
      " faure wich its tan da,\n",
      " one's awan,\n",
      " indie visser belle,\n",
      " wishon evasion undone fultz ashen rawl.\n",
      "\n",
      " eyepiece july agence tuba flagg,\n",
      " of ambon,\n",
      " undue them ochra iie,\n",
      " forgey chits ands,\n",
      " one-way shane,\n",
      " earned ivey sib l,\n",
      " with now asia noun dayne fall trey schon four aul.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range (3):\n",
    "    text = phonit(output[1])\n",
    "    text = text.replace(\"of,\",\"of \" + output[2] + \",\")\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
