{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pronouncing as pr\n",
    "import random\n",
    "from random import sample \n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import spacy\n",
    "from simpleneighbors import SimpleNeighbors\n",
    "import editdistance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Phoenetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "lookup = SimpleNeighbors(300)\n",
    "for item in nlp.vocab:\n",
    "    if item.has_vector and item.prob > -15 and item.is_lower:\n",
    "        lookup.add_one(item.text, item.vector)\n",
    "lookup.build()\n",
    "\n",
    "def vec(s):\n",
    "    return nlp.vocab[s].vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide(l):  \n",
    "    output = []\n",
    "    lengths = [3,4,5]\n",
    "    x = random.choice(lengths)\n",
    "    for i in range(0, len(l), x):  \n",
    "        output.append(l[i:i + x])\n",
    "    #print(output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phonit(text):\n",
    "    \n",
    "    text = text.split(\"\\n\")\n",
    "\n",
    "    lines = []\n",
    "    for line in text:\n",
    "        line = line.strip()\n",
    "        line = line.lower()\n",
    "        if len(line) > 0:\n",
    "            lines.append(line)\n",
    "\n",
    "    ends = []\n",
    "    for line in lines:\n",
    "        ends.append(line[-1:])\n",
    "\n",
    "    fullphon = []\n",
    "    phonemes = []\n",
    "    for line in lines:\n",
    "        doc = nlp(line)\n",
    "        for item in doc:\n",
    "            phones = pr.phones_for_word(item.text)\n",
    "            if len(phones) > 0:\n",
    "                individual_phones = phones[0].split()\n",
    "                add = []\n",
    "                for item in individual_phones:\n",
    "                    add.append(item)\n",
    "                phonemes.extend(add)\n",
    "        fullphon.append(phonemes)\n",
    "        phonemes = []\n",
    "\n",
    "    this = \"\"\n",
    "    search = \"\"\n",
    "    x = 0\n",
    "    # ' '.join(part)\n",
    "    for line in fullphon:\n",
    "        parts = divide(line)\n",
    "        for part in parts:\n",
    "            target = part\n",
    "            with_distances = [(word, phones, editdistance.eval(phones.split(), target)) for word, phones in pr.pronunciations]\n",
    "            sorted_by_dist = sorted(with_distances, key=lambda x: x[2])\n",
    "            lowest_dist = min([item[2] for item in with_distances])\n",
    "            only_lowest = [item for item in sorted_by_dist if item[2] == lowest_dist]\n",
    "            closest = random.choice(only_lowest)\n",
    "        #print(closest)\n",
    "            this = this + \" \" + closest[0]\n",
    "        this = this + ends[x] + \"\\n\"\n",
    "        x = x + 1\n",
    "    return(this)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I pledge allegiance to the Flag\n",
      "of the United States of America\n",
      "and to the Republic for which it stands,\n",
      "one nation,\n",
      "under god,\n",
      "indivisible,\n",
      "with liberty and justice for all.\n",
      "\n",
      " ip emma liege ounce tune afoul agg\n",
      " oven unites estate summum erikaa\n",
      " anette oona pub lux orth chits tanned ooze,\n",
      " one naish 'n,\n",
      " und ga ad,\n",
      " and deveaux saab eel,\n",
      " with lib ertz and jus tyce four aull.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = open(\"plaintext/pledge.txt\").read()\n",
    "\n",
    "print(text)\n",
    "print(\"\")\n",
    "print(phonit(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our Father who art in heaven,\n",
      "hallowed be thy name.\n",
      "Thy kingdom come.\n",
      "Thy will be done,\n",
      "on earth as it is in heaven.\n",
      "Give us this day our daily bread;\n",
      "and forgive us our trespasses,\n",
      "as we forgive those who trespass against us;\n",
      "and lead us not into temptation,\n",
      "but deliver us from evil.\n",
      "Amen.\n",
      "\n",
      " ours either hooge to heh auen,\n",
      " hallow beil name.\n",
      " liking demott mm.\n",
      " highway lead un,\n",
      " unearth zito's endeavor 'n.\n",
      " giver stys damer daly bread;\n",
      " undue give sour,\n",
      " aztar forgive vose huett espe sager sta ow;\n",
      " and led un ata unto tom tate 'n,\n",
      " bunda livery from evil.\n",
      " amen on.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = open(\"plaintext/prayer.txt\").read()\n",
    "\n",
    "\n",
    "print(text)\n",
    "print(\"\")\n",
    "print(phonit(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
